{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32b285f1-a25e-4c5c-9ed3-50ac51a30052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de valores (Absoluto):\n",
      "polarity\n",
      "Recommended        8179\n",
      "Mixed Feelings     1005\n",
      "Not Recommended     619\n",
      "Name: count, dtype: int64\n",
      "Distribución de clases (Porcentaje %):\n",
      "polarity\n",
      "Recommended        83.433643\n",
      "Mixed Feelings     10.251964\n",
      "Not Recommended     6.314394\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "file_name = 'reviews_complete.csv'\n",
    "\n",
    "# Se carga del Dataset\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "# Se cuentan los valores absolutos de la columna 'polarity'\n",
    "class_counts = df['polarity'].value_counts()\n",
    "print(\"Conteo de valores (Absoluto):\")\n",
    "print(class_counts)\n",
    "        \n",
    "# Se analiza porcentualmente para ver si hay desbalanceo o no\n",
    "class_percentages = df['polarity'].value_counts(normalize=True) * 100\n",
    "print(\"Distribución de clases (Porcentaje %):\")\n",
    "print(class_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ceedb31-5b0b-4a8c-9e54-0cd73772f7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity_encoded\n",
      " 1    8179\n",
      " 0    1005\n",
      "-1     619\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tittle</th>\n",
       "      <th>review_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>polarity_encoded</th>\n",
       "      <th>review_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sousou_no_Frieren</td>\n",
       "      <td>I feel so catered to.\\n\\r\\nIt feels like an et...</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>1</td>\n",
       "      <td>i feel so catered to it feels like an eternity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sousou_no_Frieren</td>\n",
       "      <td>Time is a precious thing. The most valuable re...</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>1</td>\n",
       "      <td>time is a precious thing the most valuable res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sousou_no_Frieren</td>\n",
       "      <td>Frieren: Beyond Journey's End has concluded an...</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>1</td>\n",
       "      <td>frieren beyond journeys end has concluded and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sousou_no_Frieren</td>\n",
       "      <td>The show is rated 9.37/10 on MAL at the time I...</td>\n",
       "      <td>Mixed Feelings</td>\n",
       "      <td>0</td>\n",
       "      <td>the show is rated on mal at the time i am writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sousou_no_Frieren</td>\n",
       "      <td>There are so many words I could use on how Sou...</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>1</td>\n",
       "      <td>there are so many words i could use on how sou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tittle                                        review_text  \\\n",
       "0  Sousou_no_Frieren  I feel so catered to.\\n\\r\\nIt feels like an et...   \n",
       "1  Sousou_no_Frieren  Time is a precious thing. The most valuable re...   \n",
       "2  Sousou_no_Frieren  Frieren: Beyond Journey's End has concluded an...   \n",
       "3  Sousou_no_Frieren  The show is rated 9.37/10 on MAL at the time I...   \n",
       "4  Sousou_no_Frieren  There are so many words I could use on how Sou...   \n",
       "\n",
       "         polarity  polarity_encoded  \\\n",
       "0     Recommended                 1   \n",
       "1     Recommended                 1   \n",
       "2     Recommended                 1   \n",
       "3  Mixed Feelings                 0   \n",
       "4     Recommended                 1   \n",
       "\n",
       "                                      review_cleaned  \n",
       "0  i feel so catered to it feels like an eternity...  \n",
       "1  time is a precious thing the most valuable res...  \n",
       "2  frieren beyond journeys end has concluded and ...  \n",
       "3  the show is rated on mal at the time i am writ...  \n",
       "4  there are so many words i could use on how sou...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se define el mapeo deseado para representar la polaridad positiva, negativa y neutra.\n",
    "label_map = {\n",
    "    'Recommended': 1,\n",
    "    'Mixed Feelings': 0,\n",
    "    'Not Recommended': -1\n",
    "}\n",
    "\n",
    "# Se aplica el mapeo\n",
    "df['polarity_encoded'] = df['polarity'].map(label_map)\n",
    "\n",
    "# Se muestra si todas las clases fueron mapeadas \n",
    "print(df['polarity_encoded'].value_counts(dropna=False))\n",
    "\n",
    "# Se limpia el texto aplicando modificaciones al mismo\n",
    "def clean_text_modified(text):\n",
    "    # Se convierte a minusculas\n",
    "    text = text.lower()\n",
    "    # Se eliminan saltos de línea y tabulaciones\n",
    "    text = re.sub(r'[\\r\\n\\t]+', ' ', text) \n",
    "    # Se eliminan signos de puntuación, números y caracteres especiales\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Se eliminan espacios en blanco extra\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Se aplica la función para crear la nueva columna 'review_cleaned'\n",
    "df['review_cleaned'] = df['review_text'].apply(clean_text_modified)\n",
    "\n",
    "# Se muestran las columnas originales y las nuevas columnas procesadas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07b20d67-7654-4687-ae66-f119e9ad7bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de entrenamiento: 7842\n",
      "Tamaño del dataset de test: 1961\n",
      "Tamaño del dataset de entrenamiento: 7842\n",
      "Tamaño del dataset de entrenamiento : 1961\n"
     ]
    }
   ],
   "source": [
    "# Se recoge la columna con el texto limpio \n",
    "X_networks = df['review_cleaned']\n",
    "# Se recoge la columna con el texto sin limpiar para utilizarla en el transformer\n",
    "X_transformer = df['review_text'] \n",
    "# Se recoge el valor numerico de la polaridad, es decir la columna objetivo\n",
    "y = df['polarity_encoded']\n",
    "\n",
    "# Tamaño de la separacion para las fases de entrenar y testear los modelos 80/20\n",
    "TEST_SIZE = 0.2\n",
    "# Semilla necesaria para mantener los resultados\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Se divide en Train/Test para los modelos con redes y el modelo de transformer\n",
    "X_train_networks, X_test_networks, X_train_transformer, X_test_transformer, y_train, y_test = train_test_split(\n",
    "    X_networks,\n",
    "    X_transformer,\n",
    "    y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Se comprueban los tamaños de los datasets\n",
    "print(f\"Tamaño del dataset de entrenamiento: {len(X_train_networks)}\")\n",
    "print(f\"Tamaño del dataset de test: {len(X_test_networks)}\")\n",
    "print(f\"Tamaño del dataset de entrenamiento: {len(y_train)}\")\n",
    "print(f\"Tamaño del dataset de entrenamiento : {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f84c216-77ef-4c99-83f9-49854b1dce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     9803.000000\n",
      "mean       517.219831\n",
      "std        530.065524\n",
      "min         20.000000\n",
      "25%        185.000000\n",
      "50%        348.000000\n",
      "75%        663.500000\n",
      "max      11472.000000\n",
      "Name: longitud_reseña, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Se calcula el número de palabras (tokens) en cada reseña limpia para escoger los valores que usaremos como limites para crear el tokenizador\n",
    "df['longitud_reseña'] = df['review_cleaned'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(df['longitud_reseña'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d47066d0-a524-4ece-96ee-2c2df36d0edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño X_train_padded: (7842, 512)\n",
      "Tamaño X_test_padded:  (1961, 512)\n"
     ]
    }
   ],
   "source": [
    "# Se define el tamaño del vocabulario y la longitud máxima de las secuencias en base al analisis previo\n",
    "VOCAB_SIZE = 15000 \n",
    "MAX_LENGTH = 512 \n",
    "# Token para palabras fuera del vocabulario\n",
    "OOV_TOKEN = \"<unk>\" \n",
    "\n",
    "# Se inicializa y se entrena el Tokenizer unicamente de la parte de train para evir overfitting\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=OOV_TOKEN)\n",
    "tokenizer.fit_on_texts(X_train_networks)\n",
    "\n",
    "# Se convierten los textos a secuencias de numeros\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_networks)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_networks)\n",
    "\n",
    "# Se aplica el padding para que todas las secuencias midan lo mismo añadiendo 0s o cortando la reseña si es mas grande del limite.\n",
    "X_train_padded = pad_sequences(\n",
    "    X_train_seq,\n",
    "    maxlen=MAX_LENGTH,\n",
    "    padding='post',    \n",
    "    truncating='post'  \n",
    ")\n",
    "\n",
    "X_test_padded = pad_sequences(\n",
    "    X_test_seq,\n",
    "    maxlen=MAX_LENGTH,\n",
    "    padding='post',\n",
    "    truncating='post'\n",
    ")\n",
    "\n",
    "# Se comprueba el tamaño para asegurarnos de que esta correcto\n",
    "print(f\"Tamaño X_train_padded: {X_train_padded.shape}\")\n",
    "print(f\"Tamaño X_test_padded:  {X_test_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95785d0d-33b7-4bc5-8326-f95a971f2f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestra de secuencia original al inicio: [3125, 61, 2140, 68, 168, 25, 32, 4, 49, 3275, 421, 9, 107, 55, 2]...\n",
      "Muestra de secuencia con padding al inicio: [3125   61 2140   68  168   25   32    4   49 3275  421    9  107   55\n",
      "    2]...\n",
      "Muestra de secuencia original al final: [304, 136, 151, 659, 4, 99, 33, 50, 10, 107, 16, 153, 43, 12, 21]...\n",
      "Muestra de secuencia con padding al final: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]...\n"
     ]
    }
   ],
   "source": [
    "# He comprobado diferentes reseñas para ver como ha ido el padding\n",
    "print(f\"Muestra de secuencia original al inicio: {X_train_seq[1][:15]}...\")\n",
    "print(f\"Muestra de secuencia con padding al inicio: {X_train_padded[1][:15]}...\")\n",
    "print(f\"Muestra de secuencia original al final: {X_train_seq[1][-15:]}...\")\n",
    "print(f\"Muestra de secuencia con padding al final: {X_train_padded[1][-15:]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4740599d-ca93-43b5-9295-c13866a04064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos .npy guardados: Networks_X_train.npy, Networks_X_test.npy, y_train.npy, y_test.npy\n",
      "Archivos CSV guardados: Transformer_X_train.csv, Transformer_X_test.csv\n",
      "Objeto Tokenizer guardado: keras_tokenizer.pickle\n"
     ]
    }
   ],
   "source": [
    "# Se guardan los arrays para usarlos en google collab\n",
    "np.save('Networks_X_train.npy', X_train_padded)\n",
    "np.save('Networks_X_test.npy', X_test_padded)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)\n",
    "\n",
    "print(f\"Archivos .npy guardados: Networks_X_train.npy, Networks_X_test.npy, y_train.npy, y_test.npy\")\n",
    "\n",
    "# Se guardan los textos originales (sin limpieza intensa) para el Transformer\n",
    "X_train_transformer.to_csv('Transformer_X_train.csv', index=False, header=['review_text'])\n",
    "X_test_transformer.to_csv('Transformer_X_test.csv', index=False, header=['review_text'])\n",
    "\n",
    "print(f\"Archivos CSV guardados: Transformer_X_train.csv, Transformer_X_test.csv\")\n",
    "\n",
    "# Se guarda el tokenizer para usarlo en google collab\n",
    "with open('keras_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Objeto Tokenizer guardado: keras_tokenizer.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
